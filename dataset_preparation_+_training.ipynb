{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8LKU9JSs4_z_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "41c8173c98534f49ae63f5a2afd8d69d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b3ba81bb49894fda95398e740e03f34b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_02b7cd65b3014292b3fbdd15fedba882",
              "IPY_MODEL_a5aa4d807545419793f1a9d47b5a2ebd"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "b3ba81bb49894fda95398e740e03f34b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "02b7cd65b3014292b3fbdd15fedba882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_31a4019051ec40e4ad03f49d8734ab23",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_590455886e4e4d65a59b00266e12b036"
          },
          "model_module_version": "1.5.0"
        },
        "a5aa4d807545419793f1a9d47b5a2ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d5d32342b824f37839a3bced4b9a756",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 1.98MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f484a53050884caea235c7f235db0dbc"
          },
          "model_module_version": "1.5.0"
        },
        "31a4019051ec40e4ad03f49d8734ab23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "590455886e4e4d65a59b00266e12b036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "3d5d32342b824f37839a3bced4b9a756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "f484a53050884caea235c7f235db0dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "6aa210844de74993b7d4f49fe84ac648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4be1c92b2f2a4e5183357c11fee5a198",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7952bd7ce3654e089750fc7b3ea24a09",
              "IPY_MODEL_a4bf3f81caeb4581b9eb84b361bba593"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "4be1c92b2f2a4e5183357c11fee5a198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "7952bd7ce3654e089750fc7b3ea24a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_88f4e6f5ab3c4d538a8590a5c505795e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53b5fec3ea3c48e8b996af3a2b0eedbf"
          },
          "model_module_version": "1.5.0"
        },
        "a4bf3f81caeb4581b9eb84b361bba593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88a89bd143d94790b232856347581ec7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:53&lt;00:00, 8.07B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a9c50ac76f74053bd637c40bb3ccc7e"
          },
          "model_module_version": "1.5.0"
        },
        "88f4e6f5ab3c4d538a8590a5c505795e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "53b5fec3ea3c48e8b996af3a2b0eedbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "88a89bd143d94790b232856347581ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "3a9c50ac76f74053bd637c40bb3ccc7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "2f3294b0458748e7891a1975c861ac7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4724af4c87284719a0e969b5899517db",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13879df0d9cc4952bc9c49e11f385dba",
              "IPY_MODEL_d4182e57c2f24008bbf601ae32ae1ce7"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "4724af4c87284719a0e969b5899517db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "13879df0d9cc4952bc9c49e11f385dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a452c97fbf584271a76633281edfbfff",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_191720bb449e418ca53846e5b02871b3"
          },
          "model_module_version": "1.5.0"
        },
        "d4182e57c2f24008bbf601ae32ae1ce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c7189b32e034e3589f6f529af0cbb25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:06&lt;00:00, 63.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b19bbe911e1744c58064e2e05a7c77c0"
          },
          "model_module_version": "1.5.0"
        },
        "a452c97fbf584271a76633281edfbfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "191720bb449e418ca53846e5b02871b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "9c7189b32e034e3589f6f529af0cbb25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "b19bbe911e1744c58064e2e05a7c77c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFwq1zKcI0Al"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import random\n",
        "\n",
        "import gc\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjcGhlgHLVU_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52884de-a247-4445-add6-0ffa6078195f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMA8BZNFNfAD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ac3ee8-60f9-415a-a4cb-e5c584493611"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"the device is:\",device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the device is: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LKU9JSs4_z_"
      },
      "source": [
        "## Prepare the dataset ( SQuAD )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sroa0YAOzKC"
      },
      "source": [
        "#The data class\n",
        "class Dataset():\n",
        "    def __init__(self, qac_path):\n",
        "        self.qac_path = qac_path\n",
        "\n",
        "        data_qac = pd.read_csv(qac_path)\n",
        "        data = pd.DataFrame()\n",
        "        data[\"answers\"]   = data_qac[\"answers\"]\n",
        "        data[\"questions\"] = data_qac[\"questions\"]\n",
        "        data[\"contexts\"]  = data_qac[\"contexts\"]\n",
        "        self.qac_data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.qac_data)\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "        item     = self.qac_data.loc[id]\n",
        "        answer   = item[\"answers\"]\n",
        "        question = item[\"questions\"]\n",
        "        context  = item[\"contexts\"]\n",
        "        return {\"answer\":answer, \"question\":question, \"context\":context}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeYDJCw5QaRe"
      },
      "source": [
        "#the question, answer, context csv_file path\n",
        "qac_path       = \"drive/My Drive/QCM GENERATION AI/squad2.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUrGLi_qQYA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "a76c9204-e9df-4d43-a3a3-037577f33986"
      },
      "source": [
        "#our data set\n",
        "dataset = Dataset(qac_path=qac_path)\n",
        "print(\"length:\",len(dataset))\n",
        "dataset.qac_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length: 111623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>questions</th>\n",
              "      <th>contexts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in the late 1990s</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>singing and dancing</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2003</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>Their hiatus saw the release of Beyoncé's debu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Houston, Texas</td>\n",
              "      <td>In what city and state did Beyonce  grow up?</td>\n",
              "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>late 1990s</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>Born and raised in Houston, Texas, she perform...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               answers  ...                                           contexts\n",
              "0    in the late 1990s  ...  Born and raised in Houston, Texas, she perform...\n",
              "1  singing and dancing  ...  Born and raised in Houston, Texas, she perform...\n",
              "2                 2003  ...  Their hiatus saw the release of Beyoncé's debu...\n",
              "3       Houston, Texas  ...  Born and raised in Houston, Texas, she perform...\n",
              "4           late 1990s  ...  Born and raised in Houston, Texas, she perform...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LsemakuD2X0"
      },
      "source": [
        "### IMPORTANT !!\n",
        "We are planning to use the BERT Pre-trained model, which have a maxium of 512 token per input.\n",
        "\n",
        "So the problem here is that we may have inputs ( [CLS], context, [SEP], answer, [SEP], question, [MASK] ) that contains more than 512 token.\n",
        "\n",
        "**I'm not going to change the dataset** (not going to delete the answer,question,context combinations that has more than 512 tokens ), **but in the training, we will first check if the len(input) <= 512** and then we make the forward propagation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wpbmK31FOAF"
      },
      "source": [
        "# Preparing the model ( BERT )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynM6fKDY5Pug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4592a04b-cb2a-41bc-cd1a-189e55252146"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 26.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 30.5MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 29.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 27.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 22.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 22.9MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 20.1MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 19.2MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 20.0MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 20.0MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 20.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 20.0MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 20.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 20.0MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 20.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 20.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 20.0MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 20.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 52.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 47.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=988b5998f80eb55235e92f412ea18753381b16e7a5961828e692edd0e7793a21\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfAj5YHK5ZO6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "41c8173c98534f49ae63f5a2afd8d69d",
            "b3ba81bb49894fda95398e740e03f34b",
            "02b7cd65b3014292b3fbdd15fedba882",
            "a5aa4d807545419793f1a9d47b5a2ebd",
            "31a4019051ec40e4ad03f49d8734ab23",
            "590455886e4e4d65a59b00266e12b036",
            "3d5d32342b824f37839a3bced4b9a756",
            "f484a53050884caea235c7f235db0dbc"
          ]
        },
        "outputId": "8d98ce8a-73b5-49a4-d50f-e2c5f3f1e1c0"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41c8173c98534f49ae63f5a2afd8d69d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9t3wXIU9-li",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89488d50-f859-4ce1-e086-8e8c6ae219c9"
      },
      "source": [
        "answer_ = dataset[0][\"answer\"]\n",
        "question_ = dataset[0][\"question\"]\n",
        "context_  = dataset[0][\"context\"]\n",
        "\n",
        "answer_tokens = tokenizer.tokenize(answer_)\n",
        "answer_token_ids = tokenizer.convert_tokens_to_ids(answer_tokens)\n",
        "\n",
        "question_tokens = tokenizer.tokenize(question_)\n",
        "question_token_ids = tokenizer.convert_tokens_to_ids(question_tokens)\n",
        "\n",
        "context_tokens = tokenizer.tokenize(context_)\n",
        "context_token_ids = tokenizer.convert_tokens_to_ids(context_tokens)\n",
        "\n",
        "print(f'   Answer: {answer_}')\n",
        "print(f'   Tokens: {answer_tokens}')\n",
        "print(f'Token IDs: {answer_token_ids}', end=\"\\n\\n\")\n",
        "\n",
        "print(f' Question: {question_}')\n",
        "print(f'   Tokens: {question_tokens}')\n",
        "print(f'Token IDs: {question_token_ids}', end=\"\\n\\n\")\n",
        "\n",
        "print(f'  Context: {context_}')\n",
        "print(f'   Tokens: {context_tokens}')\n",
        "print(f'Token IDs: {context_token_ids}', end=\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Answer: in the late 1990s\n",
            "   Tokens: ['in', 'the', 'late', '1990s']\n",
            "Token IDs: [1107, 1103, 1523, 3281]\n",
            "\n",
            " Question: When did Beyonce start becoming popular?\n",
            "   Tokens: ['When', 'did', 'Bey', '##on', '##ce', 'start', 'becoming', 'popular', '?']\n",
            "Token IDs: [1332, 1225, 24896, 1320, 2093, 1838, 2479, 1927, 136]\n",
            "\n",
            "  Context: Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child\n",
            "   Tokens: ['Born', 'and', 'raised', 'in', 'Houston', ',', 'Texas', ',', 'she', 'performed', 'in', 'various', 'singing', 'and', 'dancing', 'competitions', 'as', 'a', 'child', ',', 'and', 'rose', 'to', 'fame', 'in', 'the', 'late', '1990s', 'as', 'lead', 'singer', 'of', 'R', '&', 'B', 'girl', '-', 'group', 'Destiny', \"'\", 's', 'Child']\n",
            "Token IDs: [3526, 1105, 2120, 1107, 4666, 117, 2245, 117, 1131, 1982, 1107, 1672, 4241, 1105, 5923, 6025, 1112, 170, 2027, 117, 1105, 3152, 1106, 8408, 1107, 1103, 1523, 3281, 1112, 1730, 2483, 1104, 155, 111, 139, 1873, 118, 1372, 16784, 112, 188, 6405]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pi4R698tag-M"
      },
      "source": [
        "def get_bert_input(context, answer, question=\"\", max_length=512):\n",
        "    \"\"\"\n",
        "        inputs = context, answer and question\n",
        "        this function is to :\n",
        "            create our input for the bert model.\n",
        "            get the attention mask.\n",
        "            get the token type ids.\n",
        "\n",
        "        we create an input as input = [CLS], context, [SEP], answer, [SEP], question, [MASK]\n",
        "        our two segments are: segment_A : [CLS], context, [SEP], answer, [SEP]\n",
        "                              segment_B : question, [MASK]\n",
        "\n",
        "        returns a dict of:\n",
        "            input_ids: tensor( input ids )\n",
        "            attention_mask : tensor( int )\n",
        "            token type ids : tensor( int )\n",
        "    \"\"\"\n",
        "    #prepare the input as a text\n",
        "    txt = \"[CLS] \" + context + \" [SEP] \" + answer + \" [SEP] \" + question + \" [MASK]\"\n",
        "\n",
        "    #encode the inout to get the tokens\n",
        "    encoding = tokenizer.encode_plus(\n",
        "      txt,\n",
        "      add_special_tokens=True,\n",
        "      max_length=max_length,\n",
        "      return_token_type_ids=False,\n",
        "      return_tensors='pt',    \n",
        "    )\n",
        "\n",
        "    question_tokens = tokenizer.tokenize(question)\n",
        "    question_token_ids = tokenizer.convert_tokens_to_ids(question_tokens)\n",
        "\n",
        "    question_tokens.insert(0,\"\")\n",
        "    question_token_ids.append(102)\n",
        "\n",
        "\n",
        "    #delete the last [SEP]\n",
        "\n",
        "    encoding[\"input_ids\"] = encoding[\"input_ids\"][0][0:-1].view(1,-1)\n",
        "\n",
        "    #create the segment_A = [CLS] context [SEP] answer [SEP]\n",
        "    #create the segment_B = question [MASK]\n",
        "    last_sep_id = torch.nonzero(encoding[\"input_ids\"].flatten() == 102).flatten()[-1]\n",
        "    first_zero = len(encoding[\"input_ids\"][0])\n",
        "\n",
        "    segment_A = torch.zeros(last_sep_id + 1)\n",
        "    segment_B = torch.ones(first_zero - last_sep_id - 1)\n",
        "\n",
        "    #concatenate the two segments and add the padding\n",
        "    token_type_ids = torch.cat((segment_A, segment_B), 0)\n",
        "\n",
        "    return {\"input\":txt,\n",
        "            \"input_ids\":encoding[\"input_ids\"].long().to(device),\n",
        "            \"question_x\":question_tokens,\n",
        "            \"question_y\":torch.tensor(question_token_ids),\n",
        "            \"token_type_ids\":token_type_ids.long().to(device)}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uArKxhuFs1j"
      },
      "source": [
        "class Bert_QG(nn.Module):\n",
        "    def __init__(self, bert_model, config):\n",
        "        super(Bert_QG, self).__init__()\n",
        "        #the pre trained bert model\n",
        "        self.bert = bert_model          \n",
        "        self.cls = BertOnlyMLMHead(config)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "        encoder_hidden_states=None,\n",
        "        encoder_attention_mask=None,\n",
        "        output_attentions=None,\n",
        "        output_hidden_states=None):\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            encoder_hidden_states=encoder_hidden_states,\n",
        "            encoder_attention_mask=encoder_attention_mask,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "        )\n",
        "\n",
        "        #we tae the last hidden state from all the hidden states since it represent\n",
        "        #the output of the [MASK] token, and it represent the next quesry of the question\n",
        "\n",
        "        mask_out = outputs[0][0][-1]\n",
        "        prediction_score = self.cls(mask_out)\n",
        "\n",
        "        return prediction_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH-BO1Ghlqgq"
      },
      "source": [
        "Creating the model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dHd238GbcPM"
      },
      "source": [
        "# Training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_AKPP_jojBa"
      },
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "from transformers.modeling_bert import BertOnlyMLMHead\n",
        "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqYatpZ5CgJ0"
      },
      "source": [
        "def get_question_x_y(question):\n",
        "    question_x = tokenizer.tokenize(question)\n",
        "    question_token_ids = tokenizer.convert_tokens_to_ids(question_x)\n",
        "\n",
        "    question_x.insert(0,\"\")\n",
        "    question_token_ids.append(102)\n",
        "    return question_x, torch.tensor(question_token_ids).long()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ9f3amdXv54"
      },
      "source": [
        "def train_epoch_v2(model, data, loss_fn, optimizer, device, forced_teaching_rate):\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    answer   = data[\"answer\"] \n",
        "    question = data[\"question\"]\n",
        "    context  = data[\"context\"]\n",
        "\n",
        "    #here to get the length of the whole input\n",
        "    tokens = tokenizer.tokenize(\" [CLS] \"+context+\" [SEP] \"+answer+\" [SEP] \"+question+\" [SEP]\" )\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    #check if the length is under 500 ( it should be lower than 512)\n",
        "    if (len(token_ids) <= 500) and question != \"\":\n",
        "\n",
        "        #exemple:\n",
        "        #question: How are you doing ?\n",
        "        #question_x: [\"\"   , \"How\", \"are\", \"you\"  ,\"doing\", \"?\"\"]\n",
        "        #               |       |     |       |       |       |  \n",
        "        #question_y: [\"How\", \"are\", \"you\", \"doing\", \"?\"   , \"[SEP]\"]\n",
        "        question_x, question_y = get_question_x_y(question)\n",
        "\n",
        "        losses = []\n",
        "        sum_losses = 0\n",
        "\n",
        "        model = model.train()\n",
        "\n",
        "        #initialize the question\n",
        "        formed_question = \"\"\n",
        "        i = 0\n",
        "\n",
        "        forced_teaching = True if random.random() < forced_teaching_rate else False\n",
        "\n",
        "        #case of forced teaching = True\n",
        "        if forced_teaching:\n",
        "            for (q_x, q_y) in zip(question_x, question_y):\n",
        "                #we token q_x to the question\n",
        "                formed_question = formed_question + \" \" +q_x\n",
        "                #we get the full input = [CLS], context, [SEP], answer, [SEP], formed_question, [MASK]\n",
        "                X = get_bert_input(context, answer, formed_question,)\n",
        "                X_input_ids      = X[\"input_ids\"]\n",
        "                X_token_type_ids = X[\"token_type_ids\"]\n",
        "                score_prediction = model(X_input_ids,\n",
        "                                        token_type_ids=X_token_type_ids)  \n",
        "                target =  q_y.view(1).to(device)\n",
        "                loss  +=  loss_fn(score_prediction.view(1, -1),target)\n",
        "                #check if we have a memory leak, if True we backward and update weights to free memory\n",
        "                if torch.cuda.memory_allocated() > 8000000000:\n",
        "                    loss = loss / i\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "                    loss = 0\n",
        "                    i = 0\n",
        "                i += 1\n",
        "\n",
        "        else:\n",
        "            q_x = ''\n",
        "            for  q_y in  question_y:\n",
        "                #we token q_x to the question\n",
        "                formed_question = formed_question + \" \" +q_x\n",
        "                #we get the full input = [CLS], context, [SEP], answer, [SEP], formed_question, [MASK]\n",
        "                X = get_bert_input(context, answer, formed_question,)\n",
        "                X_input_ids      = X[\"input_ids\"]\n",
        "                X_token_type_ids = X[\"token_type_ids\"]\n",
        "                score_prediction = model(X_input_ids,\n",
        "                                        token_type_ids=X_token_type_ids)\n",
        "                target =  q_y.view(1).to(device)\n",
        "                loss  +=  loss_fn(score_prediction.view(1, -1),target)\n",
        "                #check if we have a memory leak, if True we backward and update weights to free memory\n",
        "                if torch.cuda.memory_allocated() > 8000000000:\n",
        "                    loss = loss / i\n",
        "                    loss.backward()\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "                    loss = 0\n",
        "                    i = 0\n",
        "                i += 1\n",
        "\n",
        "                # the next word if the output of the previous iteration\n",
        "                id  = score_prediction.argmax().item()\n",
        "                q_x = tokenizer.convert_ids_to_tokens(id)\n",
        "\n",
        "\n",
        "\n",
        "        if i > 1:\n",
        "            loss = loss / i\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        try:\n",
        "            loss.detach()\n",
        "            loss_val = loss.item()\n",
        "        except:\n",
        "            loss_val = loss\n",
        "\n",
        "        del  target, X_input_ids, X_token_type_ids, score_prediction, model, loss\n",
        "        gc.collect()\n",
        "\n",
        "        return (loss_val, forced_teaching)\n",
        "\n",
        "    return (-1,-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxOVbBlaRi5q"
      },
      "source": [
        "def evaluate(model, data, device, max_length=20):\n",
        "    answer   = data[\"answer\"]\n",
        "    context  = data[\"context\"]\n",
        "    question = data[\"question\"]\n",
        "\n",
        "    model = model.eval()\n",
        "    formed_question = \"\"\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        X = get_bert_input(context, answer, formed_question + \" [MASK]\")\n",
        "\n",
        "        X_input_ids = X[\"input_ids\"].to(device)\n",
        "        X_token_type_ids = X[\"token_type_ids\"].to(device)\n",
        "\n",
        "        score_prediction = model(X_input_ids,\n",
        "                                token_type_ids=X_token_type_ids)\n",
        "        \n",
        "        id = score_prediction.argmax().item()\n",
        "        word = tokenizer.convert_ids_to_tokens(id)\n",
        "\n",
        "        if word == \"[SEP]\":\n",
        "            break\n",
        "        formed_question += word + \" \"\n",
        "\n",
        "    X_input_ids.detach()\n",
        "    X_token_type_ids.detach()\n",
        "    torch.cuda.empty_cache()\n",
        "    del X_input_ids, X_token_type_ids\n",
        "    gc.collect()\n",
        "\n",
        "    print(\"context           :\",context)\n",
        "    print(\"answer            :\",answer)\n",
        "    print(\"Predicted question:\",formed_question)\n",
        "    print(\"Real question     :\",question)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZclQ7qxYtfK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "6aa210844de74993b7d4f49fe84ac648",
            "4be1c92b2f2a4e5183357c11fee5a198",
            "7952bd7ce3654e089750fc7b3ea24a09",
            "a4bf3f81caeb4581b9eb84b361bba593",
            "88f4e6f5ab3c4d538a8590a5c505795e",
            "53b5fec3ea3c48e8b996af3a2b0eedbf",
            "88a89bd143d94790b232856347581ec7",
            "3a9c50ac76f74053bd637c40bb3ccc7e",
            "2f3294b0458748e7891a1975c861ac7b",
            "4724af4c87284719a0e969b5899517db",
            "13879df0d9cc4952bc9c49e11f385dba",
            "d4182e57c2f24008bbf601ae32ae1ce7",
            "a452c97fbf584271a76633281edfbfff",
            "191720bb449e418ca53846e5b02871b3",
            "9c7189b32e034e3589f6f529af0cbb25",
            "b19bbe911e1744c58064e2e05a7c77c0"
          ]
        },
        "outputId": "762681fb-95e8-4a49-c16a-e2625352eb43"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "\n",
        "config = BertConfig() #the standard configuration of BERT\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME) #load the pre trained model\n",
        "\n",
        "model = Bert_QG(bert_model, config).to(device) #creating the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aa210844de74993b7d4f49fe84ac648",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f3294b0458748e7891a1975c861ac7b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H94Sm5UmZIjH"
      },
      "source": [
        "loss_fn   = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "EPOCHS = 5\n",
        "total_steps = EPOCHS * len(dataset)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23cQV5MEUzRq"
      },
      "source": [
        "### Start the training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-K4UHciZgR7"
      },
      "source": [
        "check_point = os.listdir(\"drive/My Drive/QCM GENERATION AI/check_points_v2/\")[-1]\n",
        "print(\"loaded checkpoint:\", check_point)\n",
        "model.load_state_dict(torch.load(\"drive/My Drive/QCM GENERATION AI/check_points_v2/\"+check_point))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbAP1i1yaS3o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "55edf01c-cbfa-4e6f-c535-b5381a65be28"
      },
      "source": [
        "open(\"drive/My Drive/QCM GENERATION AI/steps.txt\").read()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2500'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okIqXttpUyBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720d85ea-a15b-46ac-8623-1fd48b345831"
      },
      "source": [
        "EPOCHS = 1\n",
        "PRINT_PER = 100\n",
        "EVAL_PER = 1000\n",
        "SAVE_PER = 1000\n",
        "losses = []\n",
        "\n",
        "save_n = len(os.listdir(\"drive/My Drive/QCM GENERATION AI/check_points_v2/\"))\n",
        "step = int(open(\"drive/My Drive/QCM GENERATION AI/steps.txt\").read())\n",
        "\n",
        "while step < len(dataset):\n",
        "\n",
        "    for _ in range(1000):\n",
        "        i = random.randint(0, len(dataset))\n",
        "        data = dataset[i]\n",
        "        loss, forced_teaching = train_epoch_v2(model, data, loss_fn, optimizer, device, forced_teaching_rate=1)\n",
        "\n",
        "        if loss != -1:\n",
        "            losses.append(loss)\n",
        "\n",
        "        if step % PRINT_PER == 0:\n",
        "            print(\"[CHECK POINT] CP:\",save_n,\"    [STEP] Step:\",step,\"/\",len(dataset),\"    [LOSS] loss:\",sum(losses)/len(losses))\n",
        "            losses = []\n",
        "\n",
        "        if step % EVAL_PER == 0:\n",
        "            evaluate(model, dataset[random.randint(0, len(dataset))], device)\n",
        "\n",
        "        if step % SAVE_PER == 0:\n",
        "            print(\"SAVING MODEL..\")\n",
        "            torch.save(model.state_dict(), \"drive/My Drive/QCM GENERATION AI/check_points_v2/model_checkpoint\"+str(save_n))\n",
        "            f = open(\"drive/My Drive/QCM GENERATION AI/steps.txt\", \"w\")\n",
        "            f.write(str(step))\n",
        "            f.close()\n",
        "            print(\"MODEL SAVED \", end=\"\\n\\n\")\n",
        "            save_n = save_n + 1\n",
        "\n",
        "        step += 1\n",
        "        if step == len(dataset):\n",
        "            break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CHECK POINT] CP: 4     [STEP] Step: 2500 / 111623     [LOSS] loss: 4.81884765625\n",
            "[CHECK POINT] CP: 4     [STEP] Step: 2600 / 111623     [LOSS] loss: 4.9817125248908996\n",
            "[CHECK POINT] CP: 4     [STEP] Step: 2700 / 111623     [LOSS] loss: 4.885774617195129\n",
            "[CHECK POINT] CP: 4     [STEP] Step: 2800 / 111623     [LOSS] loss: 4.852754747867584\n",
            "[CHECK POINT] CP: 4     [STEP] Step: 2900 / 111623     [LOSS] loss: 4.898598160743713\n",
            "[CHECK POINT] CP: 4     [STEP] Step: 3000 / 111623     [LOSS] loss: 4.746620047092438\n",
            "context           : The Standard Model groups matter particles into three generations, where each generation consists of two quarks and two leptons\n",
            "answer            : The Standard Model\n",
            "Predicted question: is what is the name of the first time the first time the first time the first is used ? \n",
            "Real question     : What model has two generations?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3100 / 111623     [LOSS] loss: 5.154781892299652\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3200 / 111623     [LOSS] loss: 4.867850344181061\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3300 / 111623     [LOSS] loss: 4.887268221378326\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3400 / 111623     [LOSS] loss: 4.869467043876648\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3500 / 111623     [LOSS] loss: 4.752128758430481\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3600 / 111623     [LOSS] loss: 4.791678366661071\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3700 / 111623     [LOSS] loss: 4.973041701316833\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3800 / 111623     [LOSS] loss: 4.7918640542030335\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 3900 / 111623     [LOSS] loss: 4.905695917606354\n",
            "[CHECK POINT] CP: 5     [STEP] Step: 4000 / 111623     [LOSS] loss: 4.869572722911835\n",
            "context           : In the same lecture, he further explained that antiparticles must exist, for if particles had only positive energies, they would not be restricted to a so-called \"light cone\"\n",
            "answer            : antiparticles\n",
            "Predicted question: What is the name of the most what type of cap ##ac ? \n",
            "Real question     : What did Feynman suggest can't exist in a lecture?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4100 / 111623     [LOSS] loss: 4.709333101511001\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4200 / 111623     [LOSS] loss: 4.785132484436035\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4300 / 111623     [LOSS] loss: 4.78539133310318\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4400 / 111623     [LOSS] loss: 4.8095018935203555\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4500 / 111623     [LOSS] loss: 4.86114580154419\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4600 / 111623     [LOSS] loss: 4.903184349536896\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4700 / 111623     [LOSS] loss: 4.68579615354538\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4800 / 111623     [LOSS] loss: 4.623468813896179\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 4900 / 111623     [LOSS] loss: 4.825056583881378\n",
            "[CHECK POINT] CP: 6     [STEP] Step: 5000 / 111623     [LOSS] loss: 4.5395389795303345\n",
            "context           : The Baptist Women's College, now known as Meredith College, opened in 1891, and in 1898, The Academy of Music, a private music conservatory, was established\n",
            "answer            : 1891\n",
            "Predicted question: When did the New Haven University begin ? \n",
            "Real question     : When did Merideth College open?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5100 / 111623     [LOSS] loss: 4.54353107213974\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5200 / 111623     [LOSS] loss: 4.736739794015884\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5300 / 111623     [LOSS] loss: 4.481618905067444\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5400 / 111623     [LOSS] loss: 4.7788105797767635\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5500 / 111623     [LOSS] loss: 4.613421700000763\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5600 / 111623     [LOSS] loss: 4.661098725795746\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5700 / 111623     [LOSS] loss: 4.64766434431076\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5800 / 111623     [LOSS] loss: 4.498225438594818\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 5900 / 111623     [LOSS] loss: 4.441032328605652\n",
            "[CHECK POINT] CP: 7     [STEP] Step: 6000 / 111623     [LOSS] loss: 4.549403414726258\n",
            "context           : Tuvaluan athletes have also participated in the men's and women's 100 metre sprints at the World Championships in Athletics from 2009\n",
            "answer            : 100 metre sprints\n",
            "Predicted question: What did the two three three - years of the world ' s first - first - first ? \n",
            "Real question     : What competitions have Tuvalu athletes entered in the World Championships in Athletics?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6100 / 111623     [LOSS] loss: 4.396382118463516\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6200 / 111623     [LOSS] loss: 4.345985548496246\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6300 / 111623     [LOSS] loss: 4.524219613075257\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6400 / 111623     [LOSS] loss: 4.461315469741821\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6500 / 111623     [LOSS] loss: 4.61971155166626\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6600 / 111623     [LOSS] loss: 4.421441004276276\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6700 / 111623     [LOSS] loss: 4.443459978103638\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6800 / 111623     [LOSS] loss: 4.388611563444138\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 6900 / 111623     [LOSS] loss: 4.344509984254837\n",
            "[CHECK POINT] CP: 8     [STEP] Step: 7000 / 111623     [LOSS] loss: 4.582650349140168\n",
            "context           : Birds are also important figures in poetry; for example, Homer incorporated nightingales into his Odyssey, and Catullus used a sparrow as an erotic symbol in his Catullus 2\n",
            "answer            : nightingales\n",
            "Predicted question: What was the name of the birds that are used as a result of the torch ? \n",
            "Real question     : What did Homer incorporate into his Odyssey?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7100 / 111623     [LOSS] loss: 4.397423034906387\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7200 / 111623     [LOSS] loss: 4.450147061347962\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7300 / 111623     [LOSS] loss: 4.369453229904175\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7400 / 111623     [LOSS] loss: 4.419072018861771\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7500 / 111623     [LOSS] loss: 4.588102502822876\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7600 / 111623     [LOSS] loss: 4.629744834899903\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7700 / 111623     [LOSS] loss: 4.310997672080994\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7800 / 111623     [LOSS] loss: 4.413682563304901\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 7900 / 111623     [LOSS] loss: 4.354531254768371\n",
            "[CHECK POINT] CP: 9     [STEP] Step: 8000 / 111623     [LOSS] loss: 4.382109018564225\n",
            "context           : As the paper is opposed to the EU it has referred to foreign leaders who it deemed hostile to the UK in unflattering terms\n",
            "answer            : opposed\n",
            "Predicted question: How did the British people of the world have the British people ? \n",
            "Real question     : What is the paper's stance on the EU?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8100 / 111623     [LOSS] loss: 4.29102102637291\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8200 / 111623     [LOSS] loss: 4.319534063339233\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8300 / 111623     [LOSS] loss: 4.538382685184478\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8400 / 111623     [LOSS] loss: 4.478541271686554\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8500 / 111623     [LOSS] loss: 4.198406153321266\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8600 / 111623     [LOSS] loss: 4.547913436889648\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8700 / 111623     [LOSS] loss: 4.270611262321472\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8800 / 111623     [LOSS] loss: 4.481046602725983\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 8900 / 111623     [LOSS] loss: 4.35801474571228\n",
            "[CHECK POINT] CP: 10     [STEP] Step: 9000 / 111623     [LOSS] loss: 4.349398517608643\n",
            "context           : The proposal was never accepted and the following year France signed the Treaty of Rome, which established the European Economic Community, the precursor to the European Union\n",
            "answer            : European Union\n",
            "Predicted question: What was the treaty of Rome ? \n",
            "Real question     : To what was the European Economic Community the precurser?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9100 / 111623     [LOSS] loss: 4.3749876928329465\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9200 / 111623     [LOSS] loss: 4.299584488868714\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9300 / 111623     [LOSS] loss: 4.358219250440597\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9400 / 111623     [LOSS] loss: 4.284769742488861\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9500 / 111623     [LOSS] loss: 4.232632780075074\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9600 / 111623     [LOSS] loss: 4.247073571681977\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9700 / 111623     [LOSS] loss: 4.266916675567627\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9800 / 111623     [LOSS] loss: 4.157478342056274\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 9900 / 111623     [LOSS] loss: 4.4115793573856354\n",
            "[CHECK POINT] CP: 11     [STEP] Step: 10000 / 111623     [LOSS] loss: 4.311623405218125\n",
            "context           : \"Barometric self-esteem\" fluctuates rapidly and can cause severe distress and anxiety, but baseline self-esteem remains highly stable across adolescence\n",
            "answer            : baseline self-esteem\n",
            "Predicted question: What does the term \" The \" \" \" not use ? \n",
            "Real question     : Which type of self-esteem remains stable throughout adolescence?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10100 / 111623     [LOSS] loss: 4.255802936553955\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10200 / 111623     [LOSS] loss: 4.089947452545166\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10300 / 111623     [LOSS] loss: 4.413726133704185\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10400 / 111623     [LOSS] loss: 4.162933506965637\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10500 / 111623     [LOSS] loss: 4.079361208677292\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10600 / 111623     [LOSS] loss: 4.159881417751312\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10700 / 111623     [LOSS] loss: 4.231933941841126\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10800 / 111623     [LOSS] loss: 4.132253917455674\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 10900 / 111623     [LOSS] loss: 4.164675794839859\n",
            "[CHECK POINT] CP: 12     [STEP] Step: 11000 / 111623     [LOSS] loss: 4.135288298130035\n",
            "context           : The aspiration modifier letter may be doubled to indicate especially strong or long aspiration\n",
            "answer            : aspiration modifier\n",
            "Predicted question: What is the as ##tro ##gi ##land term for the term ? \n",
            "Real question     : What may be doubled to indicate a long aspiration?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11100 / 111623     [LOSS] loss: 4.216983221769333\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11200 / 111623     [LOSS] loss: 4.2996802282333375\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11300 / 111623     [LOSS] loss: 4.161715857982635\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11400 / 111623     [LOSS] loss: 4.1114242959022524\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11500 / 111623     [LOSS] loss: 4.208623625040055\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11600 / 111623     [LOSS] loss: 4.262322432994843\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11700 / 111623     [LOSS] loss: 4.003861652612686\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11800 / 111623     [LOSS] loss: 4.181428294181824\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 11900 / 111623     [LOSS] loss: 4.04843233704567\n",
            "[CHECK POINT] CP: 13     [STEP] Step: 12000 / 111623     [LOSS] loss: 4.0728657281398775\n",
            "context           : This artifact was later kept in the historical collections of the city until it was destroyed by the Germans in 1870 during the Franco-Prussian war\n",
            "answer            : 1870\n",
            "Predicted question: When was the first first new new new new new new new new new new new new new new new \n",
            "Real question     : In what year did the Franco-Prussian war start?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12100 / 111623     [LOSS] loss: 4.023681869506836\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12200 / 111623     [LOSS] loss: 3.8737812638282776\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12300 / 111623     [LOSS] loss: 3.808186699151993\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12400 / 111623     [LOSS] loss: 4.110174062252045\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12500 / 111623     [LOSS] loss: 3.981899995803833\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12600 / 111623     [LOSS] loss: 4.074104613065719\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12700 / 111623     [LOSS] loss: 4.096541242599487\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12800 / 111623     [LOSS] loss: 3.9120916187763215\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 12900 / 111623     [LOSS] loss: 4.10344807267189\n",
            "[CHECK POINT] CP: 14     [STEP] Step: 13000 / 111623     [LOSS] loss: 4.131310806274414\n",
            "context           : Hitler's fierce anti-Soviet rhetoric was one of the reasons why the UK and France decided that Soviet participation in the 1938 Munich Conference regarding Czechoslovakia would be both dangerous and useless\n",
            "answer            : UK and France\n",
            "Predicted question: Who did the Soviet support the Soviet support in the 1970 ' s ? \n",
            "Real question     : What countries helped the Soviets from joining the Munich Conference?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13100 / 111623     [LOSS] loss: 3.853445234298706\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13200 / 111623     [LOSS] loss: 3.954414610862732\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13300 / 111623     [LOSS] loss: 4.0935868346691135\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13400 / 111623     [LOSS] loss: 3.9513757503032685\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13500 / 111623     [LOSS] loss: 4.009738882780075\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13600 / 111623     [LOSS] loss: 4.0182639300823215\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13700 / 111623     [LOSS] loss: 4.243256145715714\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13800 / 111623     [LOSS] loss: 4.039510614871979\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 13900 / 111623     [LOSS] loss: 4.250438027381897\n",
            "[CHECK POINT] CP: 15     [STEP] Step: 14000 / 111623     [LOSS] loss: 4.0643102335929875\n",
            "context           : The rebuilding process meant that between 2001 and 2006 they were hosted at the Millennium Stadium in Cardiff in Wales\n",
            "answer            : in Cardiff in Wales\n",
            "Predicted question: Where were the first teams in the Premier League first first first created ? \n",
            "Real question     : Where is Wembley Stadium located?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14100 / 111623     [LOSS] loss: 3.7786022424697876\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14200 / 111623     [LOSS] loss: 3.8978190165758133\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14300 / 111623     [LOSS] loss: 3.9505063128471374\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14400 / 111623     [LOSS] loss: 3.803831697702408\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14500 / 111623     [LOSS] loss: 3.819601045846939\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14600 / 111623     [LOSS] loss: 3.8925921607017515\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14700 / 111623     [LOSS] loss: 3.890568335056305\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14800 / 111623     [LOSS] loss: 3.977074580192566\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 14900 / 111623     [LOSS] loss: 4.040618156194687\n",
            "[CHECK POINT] CP: 16     [STEP] Step: 15000 / 111623     [LOSS] loss: 3.936033990383148\n",
            "context           : The instrument was primarily used in a classical tradition with Mandolin orchestras, so called Estudiantinas or in Germany Zupforchestern appearing in many cities\n",
            "answer            : classical tradition with Mandolin orchestras\n",
            "Predicted question: What was the main type of music used in Germany ? \n",
            "Real question     : Where was the mandolin primarily used? \n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15100 / 111623     [LOSS] loss: 4.116472887992859\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15200 / 111623     [LOSS] loss: 4.31147952079773\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15300 / 111623     [LOSS] loss: 3.9757397103309633\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15400 / 111623     [LOSS] loss: 3.951276188492775\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15500 / 111623     [LOSS] loss: 3.9328361320495606\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15600 / 111623     [LOSS] loss: 3.9283092892169953\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15700 / 111623     [LOSS] loss: 4.016439800262451\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15800 / 111623     [LOSS] loss: 3.8659218645095823\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 15900 / 111623     [LOSS] loss: 4.0469194030761715\n",
            "[CHECK POINT] CP: 17     [STEP] Step: 16000 / 111623     [LOSS] loss: 4.077397462129593\n",
            "context           : Red was also the color associated with army; Roman soldiers wore red tunics, and officers wore a cloak called a paludamentum which, depending upon the quality of the dye, could be crimson, scarlet or purple\n",
            "answer            : paludamentum\n",
            "Predicted question: What did Roman troops do with red ? \n",
            "Real question     : What were the red tunics worn by Roman soldiers called?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16100 / 111623     [LOSS] loss: 3.8940480089187623\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16200 / 111623     [LOSS] loss: 3.8946050786972046\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16300 / 111623     [LOSS] loss: 4.004095393419266\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16400 / 111623     [LOSS] loss: 3.823902236223221\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16500 / 111623     [LOSS] loss: 4.032566868066787\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16600 / 111623     [LOSS] loss: 3.8325557637214662\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16700 / 111623     [LOSS] loss: 3.8190125036239624\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16800 / 111623     [LOSS] loss: 3.7458706402778628\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 16900 / 111623     [LOSS] loss: 4.082671018838883\n",
            "[CHECK POINT] CP: 18     [STEP] Step: 17000 / 111623     [LOSS] loss: 3.894991064071655\n",
            "context           : Napoleon was also crowned King of Italy, with the Iron Crown of Lombardy, at the Cathedral of Milan on May 26, 1805\n",
            "answer            : May 26, 1805\n",
            "Predicted question: When was Napoleon born ? \n",
            "Real question     : When was Napoleon crowned King of Italy?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17100 / 111623     [LOSS] loss: 3.846896721124649\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17200 / 111623     [LOSS] loss: 4.117092244625091\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17300 / 111623     [LOSS] loss: 4.142387007474899\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17400 / 111623     [LOSS] loss: 3.952136950492859\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17500 / 111623     [LOSS] loss: 3.907961630821228\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17600 / 111623     [LOSS] loss: 3.9938651585578917\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17700 / 111623     [LOSS] loss: 3.86954873919487\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17800 / 111623     [LOSS] loss: 3.910665000677109\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 17900 / 111623     [LOSS] loss: 3.9999442505836487\n",
            "[CHECK POINT] CP: 19     [STEP] Step: 18000 / 111623     [LOSS] loss: 3.8530766367912292\n",
            "context           : In South Africa, the number of students following Dutch at university, is difficult to estimate, since the academic study of Afrikaans inevitably includes the study of Dutch\n",
            "answer            : difficult\n",
            "Predicted question: What language was the number of students in North Africa ? \n",
            "Real question     : Is it difficult or easy to estimate the number of students in South Africa who study Dutch?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18100 / 111623     [LOSS] loss: 3.8258434665203094\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18200 / 111623     [LOSS] loss: 3.7937520587444307\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18300 / 111623     [LOSS] loss: 3.91516056060791\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18400 / 111623     [LOSS] loss: 3.8054009532928466\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18500 / 111623     [LOSS] loss: 3.8157007932662963\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18600 / 111623     [LOSS] loss: 3.756241592168808\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18700 / 111623     [LOSS] loss: 3.8048964875936506\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18800 / 111623     [LOSS] loss: 3.7851635682582856\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 18900 / 111623     [LOSS] loss: 3.947734349966049\n",
            "[CHECK POINT] CP: 20     [STEP] Step: 19000 / 111623     [LOSS] loss: 3.845684314370155\n",
            "context           : Everton's second successful era started when Harry Catterick was made manager in 1961\n",
            "answer            : Harry Catterick\n",
            "Predicted question: Arsenal Football League Football League Football League Football League Football League Football League Football League Football League Arsenal Football League \n",
            "Real question     : Who was the manager when Everton's second successful era began in 1961?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19100 / 111623     [LOSS] loss: 3.830833214521408\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19200 / 111623     [LOSS] loss: 4.040249968767166\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19300 / 111623     [LOSS] loss: 3.705610997676849\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19400 / 111623     [LOSS] loss: 3.7259620463848115\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19500 / 111623     [LOSS] loss: 3.7507735824584962\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19600 / 111623     [LOSS] loss: 3.635101087987423\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19700 / 111623     [LOSS] loss: 3.693690984249115\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19800 / 111623     [LOSS] loss: 3.792655007839203\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 19900 / 111623     [LOSS] loss: 3.8975129544734957\n",
            "[CHECK POINT] CP: 21     [STEP] Step: 20000 / 111623     [LOSS] loss: 3.6875660109519957\n",
            "context           : Its compounds are commonly encountered as copper(II) salts, which often impart blue or green colors to minerals such as azurite, malachite and turquoise and have been widely used historically as pigments\n",
            "answer            : copper(II) salts\n",
            "Predicted question: What are the most common zinc zinc zinc zinc zinc zinc and zinc ? \n",
            "Real question     : What compounds are radioactive in copper?\n",
            "SAVING MODEL..\n",
            "MODEL SAVED \n",
            "\n",
            "[CHECK POINT] CP: 22     [STEP] Step: 20100 / 111623     [LOSS] loss: 3.7417283034324647\n",
            "[CHECK POINT] CP: 22     [STEP] Step: 20200 / 111623     [LOSS] loss: 3.7331841373443604\n",
            "[CHECK POINT] CP: 22     [STEP] Step: 20300 / 111623     [LOSS] loss: 3.7838880586624146\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}